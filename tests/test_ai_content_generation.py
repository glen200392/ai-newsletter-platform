"""
æ¸¬è©¦ AI å…§å®¹ç”Ÿæˆå·¥ä½œæµï¼ˆNebula ç’°å¢ƒï¼‰
å±•ç¤ºå¦‚ä½•ç‚º CEO ç”Ÿæˆé«˜å“è³ªçš„ Newsletter å…§å®¹
"""

from datetime import datetime
from typing import Dict, List

# ============================================================================
# CEO Newsletter å…§å®¹ç”Ÿæˆå™¨
# ============================================================================

class CEONewsletterGenerator:
    """CEO Newsletter å…§å®¹ç”Ÿæˆå™¨ï¼ˆNebula ç’°å¢ƒç‰ˆæœ¬ï¼‰"""
    
    def __init__(self):
        self.newsletter_templates = {
            "strategic_intelligence": self._strategic_intelligence_template,
            "technology_radar": self._technology_radar_template,
            "market_pulse": self._market_pulse_template,
            "leadership_insights": self._leadership_insights_template
        }
    
    def generate_newsletter(
        self,
        topic: str,
        research_data: List[Dict],
        preferences: Dict = None
    ) -> Dict:
        """
        ç”Ÿæˆ Newsletter å…§å®¹
        
        åœ¨ Nebula ç’°å¢ƒä¸­ï¼Œé€™å€‹å‡½æ•¸æœƒï¼š
        1. æ•´ç†ç ”ç©¶æ•¸æ“š
        2. æ§‹å»º AI æç¤ºè©
        3. è¿”å›ç”Ÿæˆè«‹æ±‚ï¼ˆNebula æœƒè™•ç†å¯¦éš›çš„ AI ç”Ÿæˆï¼‰
        """
        
        preferences = preferences or {}
        template_func = self.newsletter_templates.get(topic)
        
        if not template_func:
            return {
                "status": "error",
                "message": f"Unknown topic: {topic}"
            }
        
        # æ§‹å»ºç”Ÿæˆè«‹æ±‚
        generation_request = template_func(research_data, preferences)
        
        return {
            "status": "success",
            "topic": topic,
            "generation_request": generation_request,
            "metadata": {
                "articles_analyzed": len(research_data),
                "generated_at": datetime.now().isoformat(),
                "preferences": preferences
            }
        }
    
    def _strategic_intelligence_template(
        self,
        research_data: List[Dict],
        preferences: Dict
    ) -> Dict:
        """Strategic Intelligence Newsletter æ¨¡æ¿"""
        
        # æ•´ç†ç ”ç©¶æ•¸æ“š
        recent_articles = sorted(
            research_data,
            key=lambda x: x.get("published", datetime.min),
            reverse=True
        )[:5]
        
        # æ§‹å»ºæç¤ºè©
        articles_summary = "\n\n".join([
            f"- {art['title']}\n  Source: {art['source']}\n  Summary: {art.get('summary', 'N/A')}"
            for art in recent_articles
        ])
        
        prompt = f"""Generate a CEO-focused Strategic Intelligence Newsletter for {datetime.now().strftime('%B %d, %Y')}.

CONTEXT:
You are writing for C-level executives who need actionable strategic insights, not just information.

RESEARCH DATA:
{articles_summary}

REQUIREMENTS:
1. **Executive Summary (30 seconds read)**
   - 3 most important strategic insights
   - One sentence each + one action implication

2. **This Week's Strategic Shifts** (3-4 minutes read)
   - Select 2-3 most significant developments
   - For each:
     * What Happened (2-3 sentences of facts)
     * Why It Matters (impact on business/industry)
     * Strategic Implication (what to consider doing)
     * Source (credible citation)

3. **Emerging Patterns** (1 minute read)
   - 1-2 weak signals worth monitoring
   - Why they matter in 2-5 year timeframe

4. **Strategic Questions for Leadership Team**
   - 3 thought-provoking questions based on the insights
   - Should challenge assumptions and drive discussion

5. **By The Numbers**
   - 3-5 key metrics/data points with interpretation

TONE: {preferences.get('tone', 'professional')}
- Professional but not academic
- Direct and action-oriented
- Evidence-based, not speculative

FORMAT:
- Bottom Line Up Front (BLUF) - most important info first
- 5-minute total read time
- Mobile-friendly (short paragraphs, clear headers)

OUTPUT STRUCTURE:
# Strategic Intelligence Weekly
## {datetime.now().strftime('%B %d, %Y')} | 5-min read

[Content follows structure above]
"""
        
        return {
            "prompt": prompt,
            "research_data": recent_articles,
            "target_length": "1200-1500 words",
            "tone": preferences.get('tone', 'professional'),
            "reading_time": "5 minutes"
        }
    
    def _technology_radar_template(
        self,
        research_data: List[Dict],
        preferences: Dict
    ) -> Dict:
        """Technology Radar Newsletter æ¨¡æ¿"""
        
        tech_articles = [
            art for art in research_data
            if art.get('category') in ['AI/ML', 'Technology', 'Developer Tools', 'Databases']
        ][:5]
        
        articles_summary = "\n\n".join([
            f"- {art['title']}\n  Source: {art['source']}\n  {art.get('summary', '')}"
            for art in tech_articles
        ])
        
        prompt = f"""Generate a Technology Radar Newsletter for non-technical CEOs.

MISSION: Translate complex technology trends into business strategy implications.

RESEARCH DATA:
{articles_summary}

STRUCTURE:

1. **Technology Maturity Assessment**
   Present 2-3 technologies in a simple matrix:
   | Technology | Maturity Level | Time to Business Impact | Action |
   
2. **Deep Dive: Featured Technology**
   - What Is It? (business definition, no jargon)
   - Why Now? (what changed to make it viable)
   - Business Model Implications (how it changes economics)
   - Who's Winning? (2 real examples with results)
   - Your Action Options:
     * Fast Follow (6 months, $XX-XXX)
     * Strategic Pilot (12 months, $X-XX)
     * Monitor & Learn (ongoing, minimal)

3. **Questions for Your CTO**
   - 3 specific technical questions based on insights
   - Help CEO drive meaningful technical discussions

TONE: Educational but not condescending
- Avoid: "Cutting-edge", "Revolutionary", "Game-changing"
- Use: Specific benefits, concrete examples, honest tradeoffs

TARGET: 7-minute read, 1500 words
"""
        
        return {
            "prompt": prompt,
            "research_data": tech_articles,
            "target_length": "1500-1800 words",
            "tone": "educational",
            "reading_time": "7 minutes"
        }
    
    def _market_pulse_template(
        self,
        research_data: List[Dict],
        preferences: Dict
    ) -> Dict:
        """Market Pulse Newsletter æ¨¡æ¿"""
        
        market_articles = [
            art for art in research_data
            if art.get('category') in ['Markets', 'Economics', 'Fintech']
        ][:5]
        
        articles_summary = "\n\n".join([
            f"- {art['title']}\n  {art.get('summary', '')}"
            for art in market_articles
        ])
        
        prompt = f"""Generate a data-driven Market Pulse Newsletter.

FOCUS: Signal over noise. CEO needs to know what matters, not every market move.

DATA:
{articles_summary}

STRUCTURE:

1. **The Week in 5 Charts**
   Describe 5 key charts/metrics:
   - Chart topic
   - Key data point
   - One-sentence interpretation
   - Business implication

2. **Three Numbers That Matter**
   | Metric | Value | Change | What It Means |
   Select metrics that are LEADING indicators

3. **Risk Monitor**
   | Risk | Level | Trend | Watch For |
   - Macro Economic
   - Geopolitical
   - Market Volatility

4. **What Smart Money Is Doing**
   - Where capital is flowing
   - Positioning changes
   - Consensus views

PRINCIPLES:
- Facts, not predictions
- Data, not opinions
- Interpretation, not investment advice

TARGET: 3-minute read, visual-first
"""
        
        return {
            "prompt": prompt,
            "research_data": market_articles,
            "target_length": "800-1000 words",
            "tone": "analytical",
            "reading_time": "3 minutes"
        }
    
    def _leadership_insights_template(
        self,
        research_data: List[Dict],
        preferences: Dict
    ) -> Dict:
        """Leadership Insights Newsletter æ¨¡æ¿"""
        
        leadership_articles = [
            art for art in research_data
            if art.get('category') in ['Leadership', 'Management']
        ][:3]
        
        articles_summary = "\n\n".join([
            f"- {art['title']}\n  {art.get('summary', '')}"
            for art in leadership_articles
        ])
        
        prompt = f"""Generate a Leadership Insights Newsletter with actionable frameworks.

PURPOSE: Extract repeatable principles from CEO experiences.

SOURCES:
{articles_summary}

STRUCTURE:

1. **Case Study: [CEO] at [Company]**
   - The Challenge (specific situation)
   - The Decision Process (how they thought through it)
   - The Action (what they did)
   - The Outcome (6-12 months later)
   - Lessons Extracted:
     * Repeatable principles
     * Avoidable mistakes
     * When this applies

2. **Framework: [Name]**
   - Visual representation
   - When to use
   - How to apply (3-step process)
   - Example application

3. **Reflection Questions**
   - Personal reflection
   - Team discussion
   - Organizational assessment

TONE: Inspiring but grounded
- Stories + Frameworks
- Humility (CEOs learn from mistakes)
- Practical application

TARGET: 10-minute read
"""
        
        return {
            "prompt": prompt,
            "research_data": leadership_articles,
            "target_length": "1800-2000 words",
            "tone": "inspirational",
            "reading_time": "10 minutes"
        }


# ============================================================================
# åŸ·è¡Œæ¸¬è©¦
# ============================================================================

def main():
    print("=" * 80)
    print("ğŸ¤– AI å…§å®¹ç”Ÿæˆå·¥ä½œæµæ¸¬è©¦ï¼ˆNebula ç’°å¢ƒï¼‰")
    print("=" * 80)
    print()
    
    # æ¨¡æ“¬å¾æ•¸æ“šæ”¶é›†ç³»çµ±ç²å–çš„ç ”ç©¶æ•¸æ“š
    mock_research_data = [
        {
            "title": "OpenAI Announces GPT-5 with Multimodal Capabilities",
            "source": "TechCrunch",
            "published": datetime(2026, 2, 4, 12, 0),
            "summary": "OpenAI unveils GPT-5, featuring advanced multimodal processing.",
            "category": "AI/ML"
        },
        {
            "title": "Fed Signals Potential Rate Cut in Q2 2026",
            "source": "Bloomberg",
            "published": datetime(2026, 2, 4, 9, 0),
            "summary": "Federal Reserve hints at possible interest rate reduction.",
            "category": "Economics"
        },
        {
            "title": "Quantum Computing Breakthrough: IBM Milestone",
            "source": "Wired",
            "published": datetime(2026, 2, 4, 8, 0),
            "summary": "IBM achieves practical error correction at scale.",
            "category": "Technology"
        },
        {
            "title": "The Future of Remote Work: Hybrid Models That Work",
            "source": "Harvard Business Review",
            "published": datetime(2026, 2, 3, 10, 0),
            "summary": "Research reveals effective hybrid work models.",
            "category": "Management"
        },
        {
            "title": "Tech Stocks Rally on Strong Earnings",
            "source": "Bloomberg",
            "published": datetime(2026, 2, 4, 6, 0),
            "summary": "Major tech companies exceed Q4 expectations.",
            "category": "Markets"
        }
    ]
    
    generator = CEONewsletterGenerator()
    
    # Test 1: Strategic Intelligence Newsletter
    print("âœ… Test 1: ç”Ÿæˆ Strategic Intelligence Newsletter")
    print("-" * 80)
    
    result1 = generator.generate_newsletter(
        topic="strategic_intelligence",
        research_data=mock_research_data,
        preferences={"tone": "professional"}
    )
    
    print(f"ç‹€æ…‹: {result1['status']}")
    print(f"ä¸»é¡Œ: {result1['topic']}")
    print(f"åˆ†ææ–‡ç« æ•¸: {result1['metadata']['articles_analyzed']}")
    print(f"ç”Ÿæˆæ™‚é–“: {result1['metadata']['generated_at']}")
    print()
    
    print("ç”Ÿæˆè«‹æ±‚é è¦½:")
    print("-" * 60)
    request = result1['generation_request']
    print(f"ç›®æ¨™é•·åº¦: {request['target_length']}")
    print(f"èªèª¿: {request['tone']}")
    print(f"é–±è®€æ™‚é–“: {request['reading_time']}")
    print(f"ä½¿ç”¨æ•¸æ“š: {len(request['research_data'])} ç¯‡æ–‡ç« ")
    print()
    print("æç¤ºè©ç‰‡æ®µï¼ˆå‰ 500 å­—å…ƒï¼‰:")
    print(request['prompt'][:500] + "...")
    print()
    
    # Test 2: Technology Radar Newsletter
    print("âœ… Test 2: ç”Ÿæˆ Technology Radar Newsletter")
    print("-" * 80)
    
    result2 = generator.generate_newsletter(
        topic="technology_radar",
        research_data=mock_research_data,
        preferences={"tone": "educational"}
    )
    
    print(f"ç‹€æ…‹: {result2['status']}")
    print(f"ä¸»é¡Œ: {result2['topic']}")
    print(f"ç›®æ¨™é•·åº¦: {result2['generation_request']['target_length']}")
    print(f"é–±è®€æ™‚é–“: {result2['generation_request']['reading_time']}")
    print()
    
    # Test 3: Market Pulse Newsletter
    print("âœ… Test 3: ç”Ÿæˆ Market Pulse Newsletter")
    print("-" * 80)
    
    result3 = generator.generate_newsletter(
        topic="market_pulse",
        research_data=mock_research_data,
        preferences={"tone": "analytical"}
    )
    
    print(f"ç‹€æ…‹: {result3['status']}")
    print(f"ä¸»é¡Œ: {result3['topic']}")
    print(f"ç›®æ¨™é•·åº¦: {result3['generation_request']['target_length']}")
    print(f"é–±è®€æ™‚é–“: {result3['generation_request']['reading_time']}")
    print()
    
    # Test 4: Leadership Insights Newsletter
    print("âœ… Test 4: ç”Ÿæˆ Leadership Insights Newsletter")
    print("-" * 80)
    
    result4 = generator.generate_newsletter(
        topic="leadership_insights",
        research_data=mock_research_data,
        preferences={"tone": "inspirational"}
    )
    
    print(f"ç‹€æ…‹: {result4['status']}")
    print(f"ä¸»é¡Œ: {result4['topic']}")
    print(f"ç›®æ¨™é•·åº¦: {result4['generation_request']['target_length']}")
    print(f"é–±è®€æ™‚é–“: {result4['generation_request']['reading_time']}")
    print()
    
    # Test 5: å±•ç¤ºå®Œæ•´çš„ Strategic Intelligence æç¤ºè©
    print("âœ… Test 5: å®Œæ•´ Strategic Intelligence æç¤ºè©ç¯„ä¾‹")
    print("-" * 80)
    print()
    print(result1['generation_request']['prompt'])
    print()
    
    # Test 6: æ¸¬è©¦ä¸åŒåå¥½è¨­å®š
    print("âœ… Test 6: æ¸¬è©¦ä¸åŒèªèª¿åå¥½")
    print("-" * 80)
    
    tones = ["professional", "conversational", "technical"]
    for tone in tones:
        result = generator.generate_newsletter(
            topic="strategic_intelligence",
            research_data=mock_research_data[:3],
            preferences={"tone": tone}
        )
        print(f"èªèª¿ '{tone}': ç”ŸæˆæˆåŠŸ âœ“")
    print()
    
    # Final Summary
    print("=" * 80)
    print("ğŸ“Š AI å…§å®¹ç”Ÿæˆå·¥ä½œæµæ¸¬è©¦æ‘˜è¦")
    print("=" * 80)
    print(f"""
âœ… Strategic Intelligence ç”Ÿæˆ: æˆåŠŸ
âœ… Technology Radar ç”Ÿæˆ: æˆåŠŸ
âœ… Market Pulse ç”Ÿæˆ: æˆåŠŸ
âœ… Leadership Insights ç”Ÿæˆ: æˆåŠŸ
âœ… å¤šèªèª¿æ”¯æŒ: æˆåŠŸ
âœ… æç¤ºè©çµæ§‹: æˆåŠŸ

é—œéµç‰¹é»:
- æ¯å€‹ä¸»é¡Œéƒ½æœ‰å°ˆé–€çš„æç¤ºè©æ¨¡æ¿
- è‡ªå‹•æ•´ç†ç ”ç©¶æ•¸æ“šç‚ºçµæ§‹åŒ–è¼¸å…¥
- æ”¯æŒå¤šç¨®èªèª¿åå¥½ï¼ˆprofessional, conversational, technicalï¼‰
- æ˜ç¢ºçš„è¼¸å‡ºçµæ§‹è¦æ±‚ï¼ˆBLUFåŸå‰‡ï¼‰
- é‡å° CEO é–±è®€ç¿’æ…£å„ªåŒ–ï¼ˆ5åˆ†é˜é–±è®€ï¼‰

åœ¨ Nebula ç’°å¢ƒä¸­çš„å·¥ä½œæµç¨‹:
1. æ•¸æ“šæ”¶é›†ç³»çµ± â†’ æ”¶é›†å¸‚å ´æƒ…å ±
2. å…§å®¹ç”Ÿæˆå™¨ â†’ æ§‹å»ºçµæ§‹åŒ–æç¤ºè©
3. Nebula AI â†’ åŸ·è¡Œå…§å®¹ç”Ÿæˆï¼ˆè‡ªå‹•ï¼‰
4. è¿”å›é«˜å“è³ª Newsletter å…§å®¹

âœ… æ‰€æœ‰ AI å…§å®¹ç”ŸæˆåŠŸèƒ½æ¸¬è©¦é€šéï¼
ç³»çµ±å·²æº–å‚™å¥½åœ¨ Nebula ç’°å¢ƒä¸­ç”Ÿæˆå°ˆæ¥­ CEO Newsletterã€‚
""")
    
    print("=" * 80)
    print()
    print("ğŸ’¡ é‡è¦æç¤ºï¼š")
    print("åœ¨ Nebula ç’°å¢ƒä¸­ï¼Œä½ ä¸éœ€è¦ç®¡ç† LLM APIï¼š")
    print("- æç¤ºè©æœƒè‡ªå‹•å‚³é€çµ¦ Nebula çš„ AI å¼•æ“")
    print("- å…§å®¹ç”Ÿæˆåœ¨å¾Œå°è‡ªå‹•å®Œæˆ")
    print("- ä½ åªéœ€è¦å°ˆæ³¨æ–¼æç¤ºè©å“è³ªå’Œå…§å®¹çµæ§‹")
    print("=" * 80)

if __name__ == "__main__":
    main()
